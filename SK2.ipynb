{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Part 2: Feature Selection and Ranking\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics of this tutorial are feature selection and feature ranking (such as \"what are the most important 5 features?\"). Feature selection is usually an overlooked issue in machine learning. In many cases, using all the descriptive features that are available can lead to excessive computational times, overfitting, and poor performance in general. It's always a good idea to check to see if we can achieve better performance by employing some sort of feature selection before fitting a model. Feature selection can also be performed in conjunction with the modeling process (as part of a machine learning pipeline), which is discussed in **SK Part 5**.\n",
    "\n",
    "## Learning Objectives\n",
    "* Perform feature selection and ranking using the following methods:\n",
    "  - F-score (a statistical filter method)\n",
    "  - Mutual information (an entropy-based filter method)\n",
    "  - Random forest importance (an ensemble-based filter method)\n",
    "  - SPSA (a new wrapper method developed by [V. Aksakalli et al.](https://arxiv.org/abs/1804.05589))\n",
    "* Compare performance of feature selection methods using paired t-tests. \n",
    "\n",
    "First, let's discuss some terminology.\n",
    "\n",
    "The classifier used to assess performance of the feature selection methods is called the \"wrapper\". Here, we use the 1-nearest neighbor as the wrapper. As for the sample data, we use the breast cancer Wisconsin dataset.\n",
    "\n",
    "The first three methods are **\"filter methods\"**: they examine the relationship between the descriptive features and the target feature and they select features only once regardless of which classifier shall be used subsequently.\n",
    "\n",
    "The last method is a **\"wrapper method\"**: it selects a different set of features for each wrapper. Wrapper feature selection methods are relatively slow and they need to be executed again when a different wrapper is used. For instance, the best 5 features selected by a wrapper method for 1-nearest neighbor will probably be different than the best 5 features for decision trees. However, wrapper methods attempt to solve the \"real problem\": \"what the best subset of features when, say, the 1-nearest neighbor classifier is used?\". They tend to perform somewhat better than the filter methods at the cost of more computational resources and a different set of features for each classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "  * [Data Preparation](#Data-Preparation)\n",
    "  * [Performance with Full Set of Features](#Performance-with-Full-Set-of-Features)\n",
    "  * [Feature Selection Using F-Score](#Feature-Selection-Using-F-Score)\n",
    "  * [Feature Selection Using Mutual Information](#Feature-Selection-Using-Mutual-Information)\n",
    "  * [Feature Selection Using Random Forest Importance](#Feature-Selection-Using-Random-Forest-Importance)\n",
    "  * [Feature Selection Using SPSA](#Feature-Selection-Using-SPSA)\n",
    "  * [Performance Comparison Using Paired T-Tests](#Performance-Comparison-Using-Paired-T-Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the dataset from the Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "\n",
    "# so that we can see all the columns\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "# for Mac OS users only!\n",
    "# if you run into any SSL certification issues, \n",
    "# you may need to run the following command for a Mac OS installation.\n",
    "# $/Applications/Python 3.x/Install Certificates.command\n",
    "# if this does not fix the issue, please run the code chunk below\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "    getattr(ssl, '_create_unverified_context', None)): \n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "cancer_url = 'https://raw.githubusercontent.com/vaksakalli/datasets/master/breast_cancer_wisconsin.csv'\n",
    "url_content = requests.get(cancer_url).content\n",
    "cancer_df = pd.read_csv(io.StringIO(url_content.decode('utf-8')))\n",
    "\n",
    "cancer_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the first 5 rows to see what the dataset looks like. Here, the last column \"diagnosis\" is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>radius_error</th>\n",
       "      <th>texture_error</th>\n",
       "      <th>perimeter_error</th>\n",
       "      <th>area_error</th>\n",
       "      <th>smoothness_error</th>\n",
       "      <th>compactness_error</th>\n",
       "      <th>concavity_error</th>\n",
       "      <th>concave_points_error</th>\n",
       "      <th>symmetry_error</th>\n",
       "      <th>fractal_dimension_error</th>\n",
       "      <th>worst_radius</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean_fractal_dimension  radius_error  texture_error  perimeter_error  \\\n",
       "0                 0.07871        1.0950         0.9053            8.589   \n",
       "1                 0.05667        0.5435         0.7339            3.398   \n",
       "2                 0.05999        0.7456         0.7869            4.585   \n",
       "3                 0.09744        0.4956         1.1560            3.445   \n",
       "4                 0.05883        0.7572         0.7813            5.438   \n",
       "\n",
       "   area_error  smoothness_error  compactness_error  concavity_error  \\\n",
       "0      153.40          0.006399            0.04904          0.05373   \n",
       "1       74.08          0.005225            0.01308          0.01860   \n",
       "2       94.03          0.006150            0.04006          0.03832   \n",
       "3       27.23          0.009110            0.07458          0.05661   \n",
       "4       94.44          0.011490            0.02461          0.05688   \n",
       "\n",
       "   concave_points_error  symmetry_error  fractal_dimension_error  \\\n",
       "0               0.01587         0.03003                 0.006193   \n",
       "1               0.01340         0.01389                 0.003532   \n",
       "2               0.02058         0.02250                 0.004571   \n",
       "3               0.01867         0.05963                 0.009208   \n",
       "4               0.01885         0.01756                 0.005115   \n",
       "\n",
       "   worst_radius  worst_texture  worst_perimeter  worst_area  worst_smoothness  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst_compactness  worst_concavity  worst_concave_points  worst_symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst_fractal_dimension diagnosis  \n",
       "0                  0.11890         M  \n",
       "1                  0.08902         M  \n",
       "2                  0.08758         M  \n",
       "3                  0.17300         M  \n",
       "4                  0.07678         M  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some pre-processing:\n",
    "- Split the dataset columns into `Data` and `target`.\n",
    "- Make target numeric by label-encoding.\n",
    "- Normalize each descriptive feature in `Data` to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = cancer_df.drop(columns = 'diagnosis').values\n",
    "target = cancer_df['diagnosis']\n",
    "Data = preprocessing.MinMaxScaler().fit_transform(Data)\n",
    "target = preprocessing.LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance with Full Set of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As wrapper, we use the 1-nearest neighbor classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we would like to assess performance using all the features in the dataset. For assessment, we shall use stratified 5-fold cross-validation with 3 repetitions. We set the random state to 999 so that our results can be replicated and verified later on exactly as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_method = RepeatedStratifiedKFold(n_splits=5, \n",
    "                                     n_repeats=3,\n",
    "                                     random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For scoring, we use the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_metric = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the cross-validation using the `cross_val_score` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_full = cross_val_score(estimator=clf,\n",
    "                             X=Data,\n",
    "                             y=target, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array `cv_results_full` contains 15 values corresponding to each one of the 3-repetition/ 5-fold combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95614035, 0.94736842, 0.95614035, 0.97368421, 0.92035398,\n",
       "       0.93859649, 0.94736842, 0.92982456, 0.98245614, 0.98230088,\n",
       "       0.94736842, 0.93859649, 0.94736842, 0.96491228, 0.95575221])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the average cross-validation performance as the mean of the `cv_results_full` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_full.mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, with the full set of features and with the 1-nearest neighbor classifier as our wrapper, we achieve an average accuracy of 95.4%.\n",
    "\n",
    "Let's now select the best 5 features in the dataset using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using F-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-Score method is a filter feature selection method that looks at the relationship between each descriptive feature and the target feature using the F-distribution. \n",
    "\n",
    "The code below returns the indices of the 5 features that have the highest F-Score value sorted from the highest to the lowest. Pay attention that the wrapper is not used in any way when selecting features using the F-Score method.\n",
    "\n",
    "In some cases, the F-Score will be \"NaN\" for some features due to technical reasons (related to the nature of the F-distribution). For this reason, we will convert any \"NaN\" value to zero for a correct result via the `np.nan_to_num()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 22,  7, 20,  2], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_fit_fscore = fs.SelectKBest(fs.f_classif, k=num_features)\n",
    "fs_fit_fscore.fit_transform(Data, target)\n",
    "fs_indices_fscore = np.argsort(np.nan_to_num(fs_fit_fscore.scores_))[::-1][0:num_features]\n",
    "fs_indices_fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what these 5 best features are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['worst_concave_points', 'worst_perimeter', 'mean_concave_points',\n",
       "       'worst_radius', 'mean_perimeter'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_fscore = cancer_df.columns[fs_indices_fscore].values\n",
    "best_features_fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the F-Scores, we observe that, out of the top 5 features, the most important feature is \"worst_concave_points\" and the least important feature is \"mean_perimeter\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-Score importances of these features are given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([964.38539345, 897.94421886, 861.67602001, 860.78170699,\n",
       "       697.23527248])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_fscore = fs_fit_fscore.scores_[fs_indices_fscore]\n",
    "feature_importances_fscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function for plotting so that we can plot other importance types as well corresponding to different feature selection methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "def plot_imp(best_features, scores, method_name, color):\n",
    "    \n",
    "    df = pd.DataFrame({'features': best_features, \n",
    "                       'importances': scores})\n",
    "    \n",
    "    chart = alt.Chart(df, \n",
    "                      width=500, \n",
    "                      title=method_name + ' Feature Importances'\n",
    "                     ).mark_bar(opacity=0.75, \n",
    "                                color=color).encode(\n",
    "        alt.X('features', title='Feature', sort=None, axis=alt.AxisConfig(labelAngle=45)),\n",
    "        alt.Y('importances', title='Importance')\n",
    "    )\n",
    "    \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b9d3ee2f3dff46a0806bb9a1202f6126\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-b9d3ee2f3dff46a0806bb9a1202f6126\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d49299f26e4f904e798a3815d2f06797\"}, \"mark\": {\"type\": \"bar\", \"color\": \"red\", \"opacity\": 0.75}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 45}, \"field\": \"features\", \"sort\": null, \"title\": \"Feature\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"importances\", \"title\": \"Importance\"}}, \"title\": \"F-Score Feature Importances\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-d49299f26e4f904e798a3815d2f06797\": [{\"features\": \"worst_concave_points\", \"importances\": 964.3853934517127}, {\"features\": \"worst_perimeter\", \"importances\": 897.9442188597812}, {\"features\": \"mean_concave_points\", \"importances\": 861.6760200073112}, {\"features\": \"worst_radius\", \"importances\": 860.7817069850568}, {\"features\": \"mean_perimeter\", \"importances\": 697.2352724765157}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_imp(best_features_fscore, feature_importances_fscore, 'F-Score', 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select those features from the set of descriptive features `Data` using slicing as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[:, fs_indices_fscore].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now assess performance of this feature selection method using cross validation with the 1-nearest neighbor classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_fscore = cross_val_score(estimator=clf,\n",
    "                             X=Data[:, fs_indices_fscore],\n",
    "                             y=target, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)\n",
    "cv_results_fscore.mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mutual information method is a filter feature selection method that looks at the relationship between each descriptive feature and the target feature using the concept of entropy.\n",
    "\n",
    "The code below returns the indices of the 5 features that have the highest mutual information value. As in the F-score method, the wrapper is not used in any way when selecting features using the mutual information method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['worst_perimeter', 'worst_area', 'worst_radius',\n",
       "       'mean_concave_points', 'worst_concave_points'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_fit_mutual_info = fs.SelectKBest(fs.mutual_info_classif, k=num_features)\n",
    "fs_fit_mutual_info.fit_transform(Data, target)\n",
    "fs_indices_mutual_info = np.argsort(fs_fit_mutual_info.scores_)[::-1][0:num_features]\n",
    "best_features_mutual_info = cancer_df.columns[fs_indices_mutual_info].values\n",
    "best_features_mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47443835, 0.46379581, 0.45331188, 0.43943754, 0.43707413])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_mutual_info = fs_fit_mutual_info.scores_[fs_indices_mutual_info]\n",
    "feature_importances_mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-c7de2e8de2bd41f9843a00fe33e1db9f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-c7de2e8de2bd41f9843a00fe33e1db9f\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9c2148786ed64794daa8fef96c29914e\"}, \"mark\": {\"type\": \"bar\", \"color\": \"blue\", \"opacity\": 0.75}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 45}, \"field\": \"features\", \"sort\": null, \"title\": \"Feature\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"importances\", \"title\": \"Importance\"}}, \"title\": \"Mutual Information Feature Importances\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-9c2148786ed64794daa8fef96c29914e\": [{\"features\": \"worst_perimeter\", \"importances\": 0.4744383537847734}, {\"features\": \"worst_area\", \"importances\": 0.46379580857169245}, {\"features\": \"worst_radius\", \"importances\": 0.4533118844776314}, {\"features\": \"mean_concave_points\", \"importances\": 0.4394375377160178}, {\"features\": \"worst_concave_points\", \"importances\": 0.43707413418609486}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_imp(best_features_mutual_info, feature_importances_mutual_info, 'Mutual Information', 'blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the performance of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.926"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_mutual_info = cross_val_score(estimator=clf,\n",
    "                             X=Data[:, fs_indices_mutual_info],\n",
    "                             y=target, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)\n",
    "cv_results_mutual_info.mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using Random Forest Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest importance (RFI) method is a filter feature selection method that uses the total decrease in node impurities from splitting on a particular feature as averaged over all decision trees in the ensemble. For classification, the node impurity is measured by the Gini index and for regression, it is measured by residual sum of squares.\n",
    "\n",
    "Let's perform RFI feature selection using 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "model_rfi.fit(Data, target)\n",
    "fs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the best features selected by RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean_concave_points', 'worst_radius', 'worst_area',\n",
       "       'worst_concave_points', 'worst_perimeter'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_rfi = cancer_df.columns[fs_indices_rfi].values\n",
    "best_features_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15683576, 0.12792458, 0.10853384, 0.10288215, 0.08206716])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_rfi = model_rfi.feature_importances_[fs_indices_rfi]\n",
    "feature_importances_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f667d5b019b946f69ad5654caef560b1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-f667d5b019b946f69ad5654caef560b1\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e72759df8676098d590dc65b521af372\"}, \"mark\": {\"type\": \"bar\", \"color\": \"green\", \"opacity\": 0.75}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 45}, \"field\": \"features\", \"sort\": null, \"title\": \"Feature\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"importances\", \"title\": \"Importance\"}}, \"title\": \"Random Forest Feature Importances\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-e72759df8676098d590dc65b521af372\": [{\"features\": \"mean_concave_points\", \"importances\": 0.1568357625505887}, {\"features\": \"worst_radius\", \"importances\": 0.12792457814392855}, {\"features\": \"worst_area\", \"importances\": 0.10853383549521228}, {\"features\": \"worst_concave_points\", \"importances\": 0.10288215260554696}, {\"features\": \"worst_perimeter\", \"importances\": 0.0820671568096089}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_imp(best_features_rfi, feature_importances_rfi, 'Random Forest', 'green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate the performance of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.926"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_rfi = cross_val_score(estimator=clf,\n",
    "                             X=Data[:, fs_indices_rfi],\n",
    "                             y=target, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)\n",
    "cv_results_rfi.mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Using SPSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPSA is a new wrapper-based feature selection method that uses binary stochastic approximation. An R implementation is available within the `spFSR` package and a Python implementation can be found on [github](https://github.com/vaksakalli/spsaml_py). Please refer to this [arxiv](https://arxiv.org/abs/1804.05589) paper for more information on this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for this example to work, you need to make sure that you download and copy the Python file `SpFtSel.py` under the same directory as your Jupyter notebook so that the import works correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a SpFtSel object with our feature selection problem with 'accuracy' as our performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpFtSel import SpFtSel\n",
    "\n",
    "sp_engine = SpFtSel(Data, target, clf, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now run the SPSA method and the indices of the best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spFtSel-INFO: Algorithm run mode: short\n",
      "spFtSel-INFO: Wrapper: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
      "                     weights='uniform')\n",
      "spFtSel-INFO: Scoring metric: accuracy\n",
      "spFtSel-INFO: Number of observations: 569\n",
      "spFtSel-INFO: Number of features available: 30\n",
      "spFtSel-INFO: Number of features to select: 5\n",
      "spFtSel-INFO: iter_no: 0, num_ft: 5, value: 0.926, st_dev: 0.023, best: 0.926 @ iter_no 0\n",
      "spFtSel-INFO: iter_no: 5, num_ft: 5, value: 0.938, st_dev: 0.011, best: 0.938 @ iter_no 5\n",
      "spFtSel-INFO: iter_no: 10, num_ft: 5, value: 0.931, st_dev: 0.01, best: 0.938 @ iter_no 5\n",
      "spFtSel-INFO: iter_no: 15, num_ft: 5, value: 0.932, st_dev: 0.018, best: 0.96 @ iter_no 12\n",
      "spFtSel-INFO: iter_no: 20, num_ft: 5, value: 0.953, st_dev: 0.02, best: 0.96 @ iter_no 12\n",
      "spFtSel-INFO: iter_no: 25, num_ft: 5, value: 0.96, st_dev: 0.013, best: 0.96 @ iter_no 12\n",
      "spFtSel-INFO: iter_no: 30, num_ft: 5, value: 0.954, st_dev: 0.003, best: 0.96 @ iter_no 12\n",
      "spFtSel-INFO: iter_no: 35, num_ft: 5, value: 0.954, st_dev: 0.003, best: 0.96 @ iter_no 12\n",
      "spFtSel-INFO: iter_no: 40, num_ft: 5, value: 0.954, st_dev: 0.003, best: 0.96 @ iter_no 12\n",
      "spFtSel-INFO: spFtSel completed in 0.11 minutes.\n",
      "spFtSel-INFO: Best value = 0.96,  Total iterations: 42\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(999)\n",
    "sp_output = sp_engine.run(num_features, run_mode='short').results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the indices of the best features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 21, 27, 23, 29], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs_indices_spsa = sp_output.get('features')\n",
    "fs_indices_spsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the top 5 features selected by SPSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['worst_radius', 'worst_texture', 'worst_concave_points',\n",
       "       'worst_area', 'worst_fractal_dimension'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_spsa = cancer_df.columns[fs_indices_spsa].values\n",
    "best_features_spsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01647079, 0.01219663, 0.01178477, 0.01035169, 0.00845075])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_spsa = sp_output.get('importance')\n",
    "feature_importances_spsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-882bc2ca5d314d11bb7d3b4afb088ac1\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-882bc2ca5d314d11bb7d3b4afb088ac1\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.2?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a85c353dd4cca06463770fc576e923e8\"}, \"mark\": {\"type\": \"bar\", \"color\": \"brown\", \"opacity\": 0.75}, \"encoding\": {\"x\": {\"type\": \"nominal\", \"axis\": {\"labelAngle\": 45}, \"field\": \"features\", \"sort\": null, \"title\": \"Feature\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"importances\", \"title\": \"Importance\"}}, \"title\": \"SPSA Feature Importances\", \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.2.json\", \"datasets\": {\"data-a85c353dd4cca06463770fc576e923e8\": [{\"features\": \"worst_radius\", \"importances\": 0.01647079015083679}, {\"features\": \"worst_texture\", \"importances\": 0.012196633248814136}, {\"features\": \"worst_concave_points\", \"importances\": 0.011784773772558436}, {\"features\": \"worst_area\", \"importances\": 0.0103516914074588}, {\"features\": \"worst_fractal_dimension\", \"importances\": 0.008450746254805509}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_imp(best_features_spsa, feature_importances_spsa, 'SPSA', 'brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate the performance of the SPSA feature selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.964"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_spsa = cross_val_score(estimator=clf,\n",
    "                             X=Data[:, fs_indices_spsa],\n",
    "                             y=target, \n",
    "                             cv=cv_method, \n",
    "                             scoring=scoring_metric)\n",
    "cv_results_spsa.mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that we get a cross-validation accuracy of 96.4% with SPSA with just 5 features. Recall that the cross-validation accuracy with the full set of features is 95.4%. So, in this particular case, it is remarkable that we can achieve even slightly better results with 5 features selected by SPSA as opposed to using all the 30 features. However, we will need to conduct a t-test to determine if this difference is statistically significant or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison Using Paired T-Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance assessment, we used repeated cross-validation. However, cross-validation is a random process and we need statistical tests in order to determine if any difference between the performance of any two feature selection methods is statistically significant; or if it is within the sample variation and the difference is statistically insignificant.\n",
    "\n",
    "Since we fixed the random state to be same for all cross-validation procedures, all feature selection methods were fitted and then tested on exactly the same data partitions. This indicates that our experiments were actually paired. Conducting experiments in a paired fashion reduces the variability significantly compared to conducting experiments in an independent fashion.\n",
    "\n",
    "Let's now conduct paired t-tests to see which differences between full set of features, filter methods, and SPSA are statistically significant. Let's first remind ourselves the performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Set of Features: 0.953\n",
      "F-Score: 0.931\n",
      "Mutual Information: 0.926\n",
      "RFI: 0.926\n",
      "SPSA: 0.964\n"
     ]
    }
   ],
   "source": [
    "print('Full Set of Features:', cv_results_full.mean().round(3))\n",
    "print('F-Score:', cv_results_fscore.mean().round(3))\n",
    "print('Mutual Information:', cv_results_mutual_info.mean().round(3))\n",
    "print('RFI:', cv_results_rfi.mean().round(3))\n",
    "print('SPSA:', cv_results_spsa.mean().round(3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a paired t-test in Python, we use the `stats.ttest_rel` function inside the `scipy` module and look at the p-values. At a 95% significance level, if the p-value is smaller than 0.05, we  conclude that the difference is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "print(stats.ttest_rel(cv_results_spsa, cv_results_fscore).pvalue.round(3))\n",
    "print(stats.ttest_rel(cv_results_spsa, cv_results_mutual_info).pvalue.round(3))\n",
    "print(stats.ttest_rel(cv_results_spsa, cv_results_rfi).pvalue.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SPSA vs. all the other three feature selection methods, we observe a p-value of 0, which indicates SPSA is statically better than F-score, mutual information, and RFI methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.053"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(cv_results_spsa, cv_results_full).pvalue.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SPSA vs. full set of features, we observe a p-value above 0.05, indicating that the difference is not statically significant. Thus, SPSA with 5 features performs at similar levels as the full set of features, at least for the 1-nearest neighbor classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In this notebook, we use all the data to train the feature selection methods and then tested them again on the entire dataset using cross-validation due to the smallness of the dataset to work with. Despite its simplicity, this approach potentially results in overfitting. In order to mitigate this issue, a more appropriate approach would be to perform this comparison within a **train/ test split approach**. Specifically, we can split the entire data into two partitions, a train and a test data. We can find the top features using the **train data** using cross-validation. Next, we can assess the performance of these features on the **test data**, again using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "www.featureranking.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
